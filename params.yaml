# params.yaml
models:
  ElasticNet:
    class: sklearn.linear_model.ElasticNet
    hyperparameters:
      alpha: [0.001, 0.01, 0.05, 0.1]
      l1_ratio: [0.1, 0.3, 0.5, 0.7, 0.9]
      random_state: [42]
  
  RandomForestRegressor:
    class: sklearn.ensemble.RandomForestRegressor
    hyperparameters:
      n_estimators: [100, 200, 300]
      max_depth: [10, 20, 30, None]
      min_samples_split: [2, 5, 10]
      random_state: [42]
  
  GradientBoostingRegressor:
    class: sklearn.ensemble.GradientBoostingRegressor
    hyperparameters:
      n_estimators: [100, 200]
      learning_rate: [0.01, 0.05, 0.1]
      max_depth: [3, 5, 7]
      random_state: [42]
  
  XGBRegressor:
    class: xgboost.XGBRegressor
    hyperparameters:
      n_estimators: [100, 200]
      max_depth: [3, 6, 9]
      learning_rate: [0.01, 0.05, 0.1]
      subsample: [0.8, 0.9, 1.0]
      random_state: [42]
  
  LGBMRegressor:
    class: lightgbm.LGBMRegressor
    hyperparameters:
      n_estimators: [100]
      max_depth: [3, 5]
      learning_rate: [0.01, 0.05]
      num_leaves: [31]
      random_state: [42]
      verbose: [-1]  # Add this to suppress logs
      silent: [True]  # Alternative for older versions

# Configuration for model training
training:
  scoring_metric: "r2"
  cv_folds: 3
  test_size: 0.2
  random_state: 42

# Model selection criteria
selection:
  primary_metric: "r2"
  secondary_metric: "rmse"
  allow_tie_breaker: True